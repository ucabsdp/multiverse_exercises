{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Transfer Learning VGG16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first investigate how to train the model via transfer learning, after this we will cleanup and encapsulate the methodolgy in a *MnistClassifier* class that allows for easy training and predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "import tensorflow.image as tf_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data, we will limit the dataset sizes for examples sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 1000\n",
    "TEST_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/spalmer/anaconda3/envs/quantum/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess to rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(images):\n",
    "    \"\"\" Preprocess grey scale image to rgb and resizes\n",
    "    \n",
    "    Args:\n",
    "        images (np.array): Array of grey scale image\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of converted images\n",
    "    \"\"\"\n",
    "    image_rgb = np.dstack((images, np.zeros_like(images), np.zeros_like(images)))\n",
    "    image_rgb = image_rgb.reshape(image_rgb.shape[0], 28, 28, 3)\n",
    "    image_rgb = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in image_rgb])\n",
    "    return image_rgb\n",
    "    \n",
    "x_train_rgb = preprocess(x_train)\n",
    "y_train_oh = to_categorical(y_train)\n",
    "\n",
    "x_test_rgb = preprocess(x_test)\n",
    "y_test_oh = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/spalmer/anaconda3/envs/quantum/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 1, 1, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rgb.shape\n",
    "train_features = model.predict(x_train_rgb[:TRAIN_SIZE])\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train simple mlp on the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 512)\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 682us/step - loss: 1.8952 - accuracy: 0.3880\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 137us/step - loss: 0.9573 - accuracy: 0.7330\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 137us/step - loss: 0.6615 - accuracy: 0.8020\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 137us/step - loss: 0.4821 - accuracy: 0.8650\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.3615 - accuracy: 0.9030\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 129us/step - loss: 0.2832 - accuracy: 0.9410\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 116us/step - loss: 0.2066 - accuracy: 0.9580\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 0.1548 - accuracy: 0.9790\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 135us/step - loss: 0.1176 - accuracy: 0.9850\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 137us/step - loss: 0.0932 - accuracy: 0.9930\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 131us/step - loss: 0.0800 - accuracy: 0.9950\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 129us/step - loss: 0.0623 - accuracy: 0.9950\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.0499 - accuracy: 0.9970\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 117us/step - loss: 0.0415 - accuracy: 0.9980\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 115us/step - loss: 0.0340 - accuracy: 0.9980\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 115us/step - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 119us/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.0217 - accuracy: 0.9990\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 115us/step - loss: 0.0160 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x65ad72048>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "shape = np.array(train_features.shape)\n",
    "train_features = np.reshape(train_features, (shape[0], shape[-1]))\n",
    "print(train_features.shape)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=512))\n",
    "model.add(Dense(500, activation='sigmoid'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# fitting the model \n",
    "\n",
    "model.fit(train_features, y_train_oh[:TRAIN_SIZE], epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets tidy this up and build it as a wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifier():\n",
    "    \"\"\" Transer learning wrapper class for classifying the Mnist data set.\n",
    "    \"\"\"\n",
    "    IMAGE_HEIGHT_ = 48\n",
    "    IMAGE_WIDTH_ = 48\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vgg16 = VGG16(weights='imagenet', include_top=False, \n",
    "                           input_shape=(self.IMAGE_HEIGHT_, self.IMAGE_WIDTH_, 3))\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(512, activation='relu', input_dim=512))\n",
    "        model.add(Dense(500, activation='sigmoid'))\n",
    "        # We will add the final dense layer one we determin the number of outputs\n",
    "        self.output_model = model\n",
    "        self.class_map = {} # Map classes to categories \n",
    "        self.trained = False\n",
    "    \n",
    "    def preprocess(self, images):\n",
    "        \"\"\" Preprocess grey scale image to rgb and resizes\n",
    "\n",
    "        Args:\n",
    "            images (np.array): Array of grey scale image\n",
    "\n",
    "        Returns:\n",
    "            np.array: Array of converted images\n",
    "        \"\"\"     \n",
    "        image_rgb = np.dstack((images, np.zeros_like(images), np.zeros_like(images)))\n",
    "        image_rgb = image_rgb.reshape(image_rgb.shape[0], 28, 28, 3)\n",
    "        image_rgb = np.asarray([img_to_array(array_to_img(im, scale=False).resize((self.IMAGE_HEIGHT_, self.IMAGE_WIDTH_))) for im in image_rgb])\n",
    "        return image_rgb\n",
    "    \n",
    "    def create_class_map(self, targets):\n",
    "        \"\"\" Store the one-hot encoding as a map.\n",
    "        \"\"\"\n",
    "        classes = list(set(targets))\n",
    "        self.class_map = {}\n",
    "        for i in range(len(classes)):\n",
    "            enc = np.zeros(len(classes))\n",
    "            enc[i] = 1\n",
    "            self.class_map[classes[i]] = enc\n",
    "        return self.class_map\n",
    "    \n",
    "    def encode(self, y):\n",
    "        \"\"\" Encode and store encoding as a map.\n",
    "        \"\"\"\n",
    "        cm = self.create_class_map(y)\n",
    "        y_one_hot = [cm[y_i] for y_i in y]\n",
    "        return np.array(y_one_hot)\n",
    "    \n",
    "    def extract_vgg16_ft(self, images):\n",
    "        \"\"\" Extract the features from vgg16.\n",
    "        \"\"\"\n",
    "        fts = self.vgg16.predict(images)\n",
    "        fts = np.reshape(fts, (fts.shape[0], fts.shape[-1]))\n",
    "        return fts\n",
    "            \n",
    "    def train(self, x, y, epochs=20):\n",
    "        \"\"\" Train the model.\n",
    "        \n",
    "        This encapsulates the full pipe, it preprocess the images and extract \n",
    "        a mapping for class labels to one-hot-encoding.\n",
    "        \"\"\"\n",
    "        x_rgb = self.preprocess(x)\n",
    "        y_one_hot = self.encode(y)\n",
    "        # add the dense output layer\n",
    "\n",
    "        self.output_model.add(layers.Dense(len(self.class_map), activation='softmax'))\n",
    "        self.output_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "        self.output_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "        \n",
    "        fts = self.extract_vgg16_ft(x_rgb)\n",
    "        self.output_model.fit(fts, y_one_hot, epochs=epochs, batch_size=128)\n",
    "        self.trained = True\n",
    "        \n",
    "    def predict(self, images):\n",
    "        \"\"\" Predict classes.\n",
    "        \"\"\"\n",
    "        assert(self.trained)\n",
    "        img_rgb = self.preprocess(images)\n",
    "        fts = self.extract_vgg16_ft(img_rgb)\n",
    "        y_ = self.output_model.predict(fts)\n",
    "        # Reverse the class map to get the predicted class label\n",
    "        rvs_map = {np.argmax(v):k for k, v in self.class_map.items()}\n",
    "        return np.array([rvs_map[np.argmax(y_i)] for y_i in y_])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on the first 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 847us/step - loss: 1.9175 - accuracy: 0.3700\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.9890 - accuracy: 0.7210\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.6737 - accuracy: 0.8010\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.4786 - accuracy: 0.8710\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 127us/step - loss: 0.3676 - accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.2857 - accuracy: 0.9360\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 123us/step - loss: 0.2187 - accuracy: 0.9590\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 121us/step - loss: 0.1695 - accuracy: 0.9770\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 0.1303 - accuracy: 0.9850\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 0.1023 - accuracy: 0.9890\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 0.0795 - accuracy: 0.9920\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 121us/step - loss: 0.0699 - accuracy: 0.9920\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0608 - accuracy: 0.9920\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.0443 - accuracy: 0.9970\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.0360 - accuracy: 0.9980\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.0308 - accuracy: 0.9990\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0263 - accuracy: 0.9990\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 121us/step - loss: 0.0228 - accuracy: 0.9990\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.0172 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "cls = MnistClassifier()\n",
    "cls.train(x_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example test of accuracy on the first 20 test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 1.0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = cls.predict(x_test[:20])\n",
    "print(pred)\n",
    "print(np.array(y_test[:20]))\n",
    "acc = sum(np.array(y_test[:20]) == pred)/len(pred)\n",
    "f'Accuracy: {acc}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
